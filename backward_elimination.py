# -*- coding: utf-8 -*-
"""Backward Elimination.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XZ_y5IXvgfWk_q9VKGvhPBOq6kX3-ZCy
"""

# REWRITE CODE FAIZ HANAFI

import pandas as pd 
csv_path ="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
headers=["sepal_length", "sepal_width", "petal_length", "petal_width", "class_label"]
datairis = pd.read_csv(csv_path, names=headers)
datairis.head()

#untuk memisa data input dan  ouput
data= datairis[["sepal_length", "sepal_width", "petal_length", "petal_width"]]
target = datairis["class_label"]

#praktikum logistic regresssion -----------

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

#masukan algoritma yang digunakan <logical regresion>
model = LogisticRegression(max_iter=1000)


#spilt datanya atau gampannya dibagi aja

x_train, x_test, y_train, y_test=train_test_split(data, target, test_size=0.2, stratify=target, random_state=5)

i = 0 #untuk index penanda (belum masuk algoritma)
feature_set = list(data.columns) #inisiasi, fitur lengkap

while (len(feature_set)>1):
      #sekedar penanda literal aja ya gan
        i = i+1
        print('putaran iterasi ke = ', i)
        #metric untuk menyimpan percobaasementar
        metric_list = []
        for feature in x_train.columns:
            if feature in feature_set:
              f_set=feature_set.copy() #copy fiturset biar gak berubah2 
              f_set.remove(feature) # hapus fitur dalam fitur set
              print(f_set)
              model.fit(x_train[f_set], y_train)
              uji=model.predict(x_test[f_set]) #test model
              akurasi = accuracy_score(y_test, uji)
              print(akurasi)
              metric_list.append((akurasi, feature)) # simpan data akurasi dan fiturnya

         # dengan kasus bahwa semakin besar akurasi semakin baik, sort dr yang terbesar
        metric_list.sort(key=lambda x : x[0], reverse = True)
        #update aja nih fitursetnya dengan hapus fitur yang telah dihapus
        feature_set.remove(metric_list[0][1])

### kode diatas kode untuk algortima backward ------------------

#  KODE BARIS ALGORITMA FORWARD SELECTION

n = len(list(data)) # hanya penanda variable
i=0 # untuk penanda index
feature_set = []

for num_features in range(n):
  #hanya sekedar penanda iterasi pengulangan 
  i=i+1
  print('putaran ke =' ,i)
  #simpan sementara
  metric_list = []
  for feature in x_train.columns:
    if feature not in feature_set:
      f_set = feature_set.copy() # copy fitur set supaya tidak berubah
      f_set.append(feature) #tambah fitur
      print(f_set)
      model.fit(x_train[f_set], y_train) #bangun model dgn fitur yang telah ditambahin
      uji=model.predict(x_test[f_set]) #test modelnya
      akurasi = accuracy_score(y_test, uji)
      print(akurasi)
      metric_list.append((akurasi, feature)) # simpan data akurasi

  metric_list.sort(key=lambda x : x[0], reverse = True)
  #update fitur set 
  feature_set.append(metric_list[0][1])